{"componentChunkName":"component---src-pages-index-jsx","path":"/","result":{"data":{"site":{"siteMetadata":{"name":"Humza Ahmad","title":"Humza Ahmad | Machine Learning Engineer","description":"Machine Learning Engineer with expertise in Computer Vision and Natural Language Processing","about":"Machine Learning Engineer with Computer Vision and NLP expertise with 3+ years experience in data science, machine learning system development and deployment.\n    \n    Expertise:\n    \n    - Computer Vision\n    - Semantic and Instance Segmentation\n    - Object Tracking, Recognition and Detection\n    - Image Classification\n    - Natural Language Processing\n    - Sentiment Textual Similarity\n    - Sentiment Analysis\n    - Text Classification\n    - Statistical Data Analytics\n    - Unsupervised Learning Techniques\n    - Recommendation system\n    - Data visualization and cleaning\n    \n    Skills:\n    \n    - Libraries and Frameworks: Scikit-learn, PyTorch, TensorFlow, Hugging Face, NumPy, Pandas, Matplotlib, Seaborn, Jupyter Notebook, Anaconda, Flask, Django, NLTK, Open-CV\n    - Algorithms: Deep Neural Networks, Convolutional Neural Networks, Transformers, BERT, T5, Recurrent Neural Networks, Linear Regression, Logistic Regression, Support Vector Machines, Naive Bayes, KNN, Decision Tree, Random Forest, Gradient Boosting, Principal Component Analysis, KMeans\n    - Programming languages: Python, C++\n    - Work management tools: Jira, Confluence, Trello\n    - DevOps Tools: Git, Docker, Google Cloud Platform (GCP), Amazon Web Services (AWS)\n    - Database Technologies: PostgreSQL, MySQL, Redis\n    - Front-end Technologies: HTML, Bootstrap, CSS, Javascript and ReactJs.","author":"@iamhamzu906","github":"https://github.com/humzaahmad906","linkedin":"https://www.linkedin.com/in/humza-ahmad-7a2830130/","projects":[{"name":"Hellofact","description":"Implement Recursive WebCrawler and Search Engine for Legal Casino documents.\n            Search Engine has Download, OCR, Name Entity Recognition Tagging and Indexing functionalities.\n            ▪ Download pipeline using Requests, ThreadPool, Selenium and Zen-scrape.\n            ▪ OCR of Pdf files using Tesseract OCR and Abbyy to convert into raw text and styled\n            documents.\n            ▪ NER pipeline using HuggingFace to get categories of sub-documents.\n            ▪ Indexing pipeline to index text document into MongoDB and Pinecone respectively with GPT3 ADA-002 Embeddings for further use.\n            ▪ Information Retrieval and Search pipeline to retrieve best results for search query from indexed documents with GPT3 ADA-002 Embeddings and generate answers using GPT3 Davinci-003 Completion API.","link":"https://github.com/RyanFitzgerald/devfolio"},{"name":"Person Identification in multi-camera system","description":"The aim of this project was to track a person on multi-camera setup such that its ID\nremains constant. Working of this pipeline is as follows.\n▪ Person face and body embeddings will be registered in redis and mysql server when\nthe person first appears in the frame.\n▪ Before Registration the pipeline will check whether the face is registered in current\ndatabase by taking cosine similarity of his embeddings with previously added\nembeddings.\n▪ When the server gets closed, all the face and body embeddings will be reloaded from\nmysql server to redis.","link":"https://github.com/RyanFitzgerald/devfolio"},{"name":"Background Remover","description":"Implement end-to-end pipeline for background removal task. Fine-tune Mask-RCNN and\nYolact for automatic background removal and implement from scratch f-BRS\n(Rethinking Background Refinement for Segmentation) and Super-pixel plus grab cut\nalgorithm for interactive image segmentation.\n▪ Collect, clean, and pre-process the data and convert it to universal coco format for\ntraining Image Segmentation models.\n▪ Implement interactive segmentation pipeline using Super-pixel to divide each image\ninto big chunks and used grab cut algorithm for the foreground chunks separation\nwith Scikit-learn and OpenCV.\n▪ Fine-tuned f-BRS model for interactive segmentation with fewer clicks.\n▪ Mask-RCNN and Yolact fine-tuning to get foreground mask for automatic\nbackground removal.\n▪ Deep alpha matting for smoother foreground masks.","link":"https://chromeextensionkit.com/?ref=devfolio"},{"name":"Health-app","description":"Prediction of meal plan and exercise required to gain or lose weight.\n▪ Train XGBoost classifier to predict duration of exercise from previous exercise\nduration, original weight, required weight and height.\n▪ Train classifier to predict intake calories from the same features.\n▪ After prediction of calories intake we use Nearest Neighbor algorithm to get the\nmeal-plan from fit-bit data-set of the closest intake calories.","link":"https://github.com/RyanFitzgerald/devfolio"},{"name":"Semantic Textual Similarity","description":"Implement training and prediction BERT base and Roberta using HuggingFace and Pytorch for Semantic Similarity and match it to categorize FAQ answers\n            ▪ Data preprocessing and post-processing using Pandas and Numpy.\n            ▪ Fine-tune and Validate both the models using HuggingFace and Pytorch.\n            ▪ Train both the models and compared the Accuracy, F1-score, Recall, and Precision\n            metrics.","link":"https://github.com/RyanFitzgerald/devfolio"},{"name":"FNIR based activity segmentation","description":"Classification on different difficulty level tasks using machine learning and statistical\n              techniques on data-set got from 12 near-infrared sensors that are used to measure\n              oxidized and deoxidized hemoglobin. Use the classification report to get the best model.\n              ▪ Clean time steps that contained no information about the difficulty levels.\n              ▪ Select windows of variable lengths to derive features like mean, median, max, min,\n              skewness to convert 24 features to 120 features.\n              ▪ Use feature selection to extract the best 50 features from 120.\n              ▪ Implement SVM, Polynomial Regression, and Artificial Neural Networks in Scikit-\n              learn and Keras. PCA and LDA implementation for dimensionality reduction.\n              ▪ Train and validate the data-set using Accuracy, F1-score, Recall, and Precision\n              metrics. Select the best window length using the scores on validation data.","link":"https://github.com/RyanFitzgerald/devfolio"},{"name":"Tumor Segmentation","description":"Implement training and prediction pipeline of vanilla U-Net and V3 Inception based U-\n              Net for image segmentation of benign and malignant tumors.\n              ▪ Data pre-processing and post-processing using Pandas and Numpy.\n              ▪ Implement U-Net with V3 inception modules and vanilla U-Net using python andTensorFlow.\n              ▪ Train both the models and compared the Accuracy, MIOU, F1-score, Recall,\n              Precision, and Dice Coefficient metrics.\n              ▪ Validate both models and hyper-parameter tuning to get better results.","link":"https://github.com/RyanFitzgerald/devfolio"}],"experience":[{"name":"Acme Corp","description":"Full-Stack Developer, February 2020 - Present","link":"https://github.com/RyanFitzgerald/devfolio"},{"name":"Globex Corp","description":"Full-Stack Developer, December 2017 - February 2020","link":"https://github.com/RyanFitzgerald/devfolio"},{"name":"Hooli","description":"Full-Stack Developer, May 2015 - December 2017","link":"https://github.com/RyanFitzgerald/devfolio"}],"skills":[{"name":"Languages & Frameworks","description":"JavaScript (ES6+), Golang, Node.js, Express.js, React, Ruby on Rails, PHP"},{"name":"Databases","description":"MongoDB, PostreSQL, MySQL"},{"name":"Other","description":"Docker, Amazon Web Services (AWS), CI / CD, Microservices, API design, Agile / Scrum"}]}},"allMarkdownRemark":{"edges":[{"node":{"excerpt":"Lorem ipsum dolor sit amet consectetur adipisicing elit Lorem ipsum dolor sit amet consectetur adipisicing elit. Unde reprehenderit…","fields":{"slug":"/blog/my-fourth-blog/"},"frontmatter":{"date":"October 12, 2020","title":"My Fourth Blog Post","description":"Unde reprehenderit inventore sunt, consequatur"}}},{"node":{"excerpt":"Lorem ipsum dolor sit amet consectetur adipisicing elit Lorem ipsum dolor sit amet consectetur adipisicing elit. Unde reprehenderit…","fields":{"slug":"/blog/my-third-blog/"},"frontmatter":{"date":"October 10, 2020","title":"My Third Blog Post","description":"Dolor inventore quasi necessitatibus odio eaque doloribus"}}},{"node":{"excerpt":"Lorem ipsum dolor sit amet consectetur adipisicing elit Lorem ipsum dolor sit amet consectetur adipisicing elit. Unde reprehenderit…","fields":{"slug":"/blog/my-second-blog/"},"frontmatter":{"date":"October 02, 2020","title":"My Second Blog Post","description":"Ratione dolore sequi in animi obcaecati incidunt reprehenderit illo repellat"}}},{"node":{"excerpt":"Lorem ipsum dolor sit amet consectetur adipisicing elit Lorem ipsum dolor sit amet consectetur adipisicing elit. Unde reprehenderit…","fields":{"slug":"/blog/my-first-blog/"},"frontmatter":{"date":"September 20, 2020","title":"My First Blog Post","description":"Ducimus perferendis porro cumque ea error ab voluptatem"}}}]}},"pageContext":{}},"staticQueryHashes":["63159454"]}